
# SAE for LLM Interpretability

## References

1. **Title:** *Explaining in Style: Training a GAN to Explain a Classifier in Style Space*  
   **Authors:** Shane Barratt, Rishi Sharma  
   **Link:** [arXiv:2006.13913](https://arxiv.org/abs/2006.13913)


---

## Paper Summaries

### 1. *Explaining in Style: Training a GAN to Explain a Classifier in Style Space*

**Method:**  
The authors propose using Generative Adversarial Networks (GANs) to explain classifier decisions by operating in the style space of the data. The GAN learns to manipulate style features that influence the classifier's decision, providing a visual explanation of what the model is focusing on.

**Results:**  
The method demonstrates that style manipulation can highlight critical features influencing model predictions, offering an interpretable and intuitive understanding of complex classifiers.
