# LLM SAMPLING

## References

1. **Title:** *Chain-of-Thought Reasoning without Prompting*  
   **Authors:** Xuezhi Wang and Denny Zhou
   **Link:** [https://arxiv.org/pdf/2402.10200]


---

## Paper Summaries

### 1. *Chain-of-Thought Reasoning without Prompting*

**Method:**   CoT decoding which extracts CoT paths among the decoded paths
from the model.

> **Notes:** 'is it still top-k?' 'how to generalize answer-span method in other task?'
